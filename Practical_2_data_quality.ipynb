{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-KgjGRdNcj4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Sequence, Literal\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn9RFhjb70IJ"
   },
   "source": [
    "#Question 1: Handling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO7NYNsI_0Hz"
   },
   "source": [
    "Last session we recording gaze data using different devices. Today we are going to look at how to analyze that data. The very first, **absolutely essential** step that **must never be left out in any data science project** is to check data quality.\n",
    "\n",
    "We will perform the following steps:\n",
    "- Load and parse the recorded data of all groups.\n",
    "- Perform a basic data quality analysis for all datasets:\n",
    "  - What is the sampling rate (Hz)\n",
    "  - Is the sampling rate constant?\n",
    "  - Are all recordings of the same (or similar) length? If not, should they?\n",
    "  - Calculate the tracking rate, i.e., the ratio of valid gaze samples.\n",
    "  - Calculate spatial accuracy and precision.\n",
    "- Are there differences between groups? What is the source of these differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-aaGrs81n_gN"
   },
   "outputs": [],
   "source": [
    "# Run this line to download the data to your Colab runtime environment.\n",
    "!wget https://raw.githubusercontent.com/kueblert/gazeinteraction/master/yarbus_recordings.zip\n",
    "!unzip yarbus_recordings.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBxohZo9954j"
   },
   "source": [
    "**Question 1.b. (2 points)** Unify the data format. We want to later on use the same routines to process data from all recordings. Therefore, inherit from and implement the following class for each data format.\n",
    "\n",
    "Use the other groups' readme files to interpret the data. In case it is insufficient or hard to understand, please let them know and get the missing info from them (**in a friendly way!**). Not all devices report binocular data. In that case, just use the same data for each eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQQmm9_ZQwzf"
   },
   "outputs": [],
   "source": [
    "class GazeDataset:\n",
    "  def __init__(self, filename: str):\n",
    "    # load a single recording from a file\n",
    "    pass\n",
    "\n",
    "  def x(eye: Literal[\"left\", \"right\"]) -> pd.DataFrame:\n",
    "    # the horizontal gaze coordinate on screen [pixels] for the left/right eye\n",
    "    pass\n",
    "\n",
    "  def y(eye: Literal[\"left\", \"right\"]) -> pd.DataFrame:\n",
    "    # the vertical gaze coordinate on screen [pixels] for the left/right eye\n",
    "    pass\n",
    "\n",
    "  def timestamp() -> pd.DataFrame:\n",
    "    # the timestamp in milliseconds\n",
    "    pass\n",
    "\n",
    "  def validity(eye: Literal[\"left\", \"right\"]) -> pd.DataFrame:\n",
    "    # whether a sample (of the left/right eye, if distinguishable) is valid or not\n",
    "    pass\n",
    "  \n",
    "  def stimulus() -> pd.DataFrame:\n",
    "    # which image / task was displayed to the subject\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doP-Nw9ASNSf"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kk6N3wURHMP"
   },
   "outputs": [],
   "source": [
    "# Helper code to apply a specific function f to all data within the dataset\n",
    "# You will need to adjust paths and class names, but should be ready to work with otherwise.\n",
    "\n",
    "dataset_paths = [\"group1\", \"group2\", \"group3\"]\n",
    "class_types = [GazeDatasetG1, GazeDatasetG2, GazeDatasetG3]\n",
    "\n",
    "# probably no changes necessary from here on\n",
    "import glob\n",
    "\n",
    "def apply_to_datasets(f):\n",
    "  results = []\n",
    "  # iterate over all groups\n",
    "  for dataset_path, dataset_class in zip(dataset_paths, class_types):\n",
    "    group = []\n",
    "    # iterate over all recordings by that group\n",
    "    for recording_filename in glob.glob(\"yarbus_recordings/%s/*.csv\" % dataset_path):\n",
    "      # parse the dataset\n",
    "      dataset = dataset_class(recording_filename)\n",
    "      # apply function to dataset\n",
    "      group.append(f(dataset))\n",
    "    results.append(group)\n",
    "  return results\n",
    "\n",
    "def print_length(d: GazeDataset):\n",
    "  print(len(d.timestamp()))\n",
    "\n",
    "apply_to_datasets(print_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXbuykDaBb3e"
   },
   "source": [
    "# Question 2: Sampling rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAJ8bRBqHz4D"
   },
   "source": [
    "The sampling rate of an eye tracker is important for knowing what type of events you can measure and which event detection algorithm is appropriate. A rule of thumb is the *Nyquist-Shannon sampling theorem* (Shannon, 1949) which states that the sampling frequency should be at least twice the speed of the particular eye movement.\n",
    "\n",
    "But we cannot simply tell sampling rate from device type, as they often support multiple settings and performance bottlenecks in the recording hardware might have an effect as well.\n",
    "\n",
    "**Question 2.a. (1 point)** In the following code snippets, determine the average duration (in milliseconds) between data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nm5kjQC6Jujh"
   },
   "outputs": [],
   "source": [
    "#Function for calculating the average ms between samples\n",
    "def mean_duration_between_samples(data: GazeDataset) -> float:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ad4cKOgititO"
   },
   "source": [
    "**Question 2.b. (1 point)** In the following code snippets, determine the sampling frequency, i.e., the number of samples per second that the device recorded (in Hz), of the eye tracker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1xdrYLy5mkh"
   },
   "outputs": [],
   "source": [
    "#Function for calculating the sampling rate (samples per second)\n",
    "def sampling_rate(time_between_samples: float) -> int:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypPYQ6eLSfU9"
   },
   "source": [
    "**Question 2.c. (1 point)** Is the sampling rate (reasonably) constant within each group?\n",
    "\n",
    "*Why we check this: Often data is recorded with more than one device. As sampling rate is a manual setting, it might be configured differently on the recording devices. Perhaps one recording laptop quit service inmidst of the experiment and the settings needed to be reconfigured on a second device, so some data is sampled differently? You need to know that!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csf4c42ISek_"
   },
   "outputs": [],
   "source": [
    "def sampling_rate_variance(data: GazeDataset) -> float:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCcmE9JdKBpi"
   },
   "source": [
    "**Question 2.d. (3 points):** For the next code snippet, write a function that resamples the data at a different sampling rate. Use a linear interpolation for this purpose. Resample the data to **60Hz**.\n",
    "\n",
    "*In case your data is sampled inconsistently, it is always possible to downsample to the lowest sampling rate in your data. Upsampling would mean making up new values and should be avoided.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXUgWHvGKGJ5"
   },
   "outputs": [],
   "source": [
    "#Function for Down sampling to another sampling rate\n",
    "def resample(data: GazeDataset, target_sampling_rate: float = 60) -> GazeDataset:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7lLvg7MJ4PP"
   },
   "source": [
    "**Question 2.c. (1 point):** Do you think it's an adequate sampling rate for analyzing saccades? Support your answer with 1 sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9CgNyYp0xi6"
   },
   "source": [
    "**Answer:** your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7yrhCNaW1Jn"
   },
   "source": [
    "##Question 3: Tracking ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECBEixX9TsG3"
   },
   "source": [
    "**Question 2: (2 points)** Measurement devices might be unable to acquire a good measurement under some conditions (eyeglasses, lightning, headbox too small). In some cases the device knows a measurement error has occurred and reports that. In other cases such a failure happens silently. Calculate the tracking rate, i.e., the ratio of reported valid samples versus all samples.\n",
    "Return the tracking rates for both eyes separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGVQQJy_UM3v"
   },
   "outputs": [],
   "source": [
    "def tracking_ratio(data: GazeDataset) -> Tuple[float, float]:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCLp7Ye8URC-"
   },
   "source": [
    "- Are there differences between devices? Possibly even between groups using the same devices?\n",
    "- What are possible causes of such tracking errors?\n",
    "- Are there certain characteristics observable (e.g., are there many individual losses or are there segments where tracking failed for a longer time)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5Mdnz0VHl8H"
   },
   "source": [
    "## Question 3: Accuracy and precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UuXbV8EH1w6"
   },
   "source": [
    "**Question 3.a. (3 point):** For the analysis of accuracy and precision we need to know where the subject is looking at. Accuracy is the measure of how good the eye-tracker hits that point (on average). Precision is a measure of how far the samples spread around that point). \n",
    "\n",
    "We recorded such an episode during the fixation cross phase of the experiment.\n",
    "Extract data segments during the first fixation cross phase.\n",
    "Ideally, drop the first 200 ms of data. This phase might not contain a fixation towards the fixation cross just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ql38yCCxLfLC"
   },
   "outputs": [],
   "source": [
    "def extract_fixation_cross(data: GazeDataset) -> GazeDataset:\n",
    "  # Extracts the time segment during which the first fixation cross was displayed\n",
    "  # your code here\n",
    "  pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm5pZL_SWfs3"
   },
   "source": [
    "Calculate accuracy and precision, for each eye separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsbPKTVjVK9m"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(data: GazeDataset, target: Tuple[int, int]) -> Tuple[float, float]:\n",
    "  # your code here\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYcWaoOtVW0H"
   },
   "outputs": [],
   "source": [
    "def calculate_precision(data: GazeDataset) -> Tuple[float, float]:\n",
    "  # your code here\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hP8zs44wacS"
   },
   "source": [
    "**Question 3.b.: (1 point)** Visualize the accuracy per group using a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_wd6jbewmAq"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OEuptpVWk33"
   },
   "source": [
    "Are there differences between both eyes? If so, what are possible explanations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYVjWK8exKHi"
   },
   "source": [
    "# Question 4: Visualize! (Bonus)\n",
    "Visualization is the probably most powerful tool to immediately see a lot of potential problems with the data.\n",
    "\n",
    "- Select a single dataset of your choice.\n",
    "- Visualize gaze samples on the stimulus image. Be careful with where on the screen the stimulus was displayed.\n",
    "- Visualize only valid data.\n",
    "- Each sample should be marked by a small dot / colorful pixel.\n",
    "- The stimulus should be visible in the background."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practical_2_data_quality.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
